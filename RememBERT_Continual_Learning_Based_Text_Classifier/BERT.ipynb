{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7m5iPfVANhfa"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "from collections import OrderedDict\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from typing import Union, Tuple, List, Iterable, Dict\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "import numpy as np\n",
        "import gzip, csv\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45kZv80K968l",
        "outputId": "32d327e3-4730-476e-883a-09d2694aabb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 multiprocess-0.70.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers\n",
        "from transformers import AutoTokenizer\n",
        "# If you can not find all the bugs, use the line below for AutoModel\n",
        "#from transformers import AutoModel\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pPDJEnvNsjR",
        "outputId": "ad849cfd-9c4f-439e-e137-ff9b416b364f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install avalanche-lib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbyQ_X_a7ma3",
        "outputId": "cfec7bca-6043-42b9-a4fb-1100d3e08e35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting avalanche-lib\n",
            "  Downloading avalanche_lib-0.5.0-py3-none-any.whl (971 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m971.9/971.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from avalanche-lib) (4.10.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from avalanche-lib) (5.9.5)\n",
            "Collecting gputil (from avalanche-lib)\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from avalanche-lib) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from avalanche-lib) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from avalanche-lib) (1.25.2)\n",
            "Collecting pytorchcv (from avalanche-lib)\n",
            "  Downloading pytorchcv-0.0.67-py2.py3-none-any.whl (532 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.4/532.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from avalanche-lib)\n",
            "  Downloading wandb-0.16.4-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=1.15 in /usr/local/lib/python3.10/dist-packages (from avalanche-lib) (2.15.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from avalanche-lib) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from avalanche-lib) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from avalanche-lib) (0.16.0+cu121)\n",
            "Collecting torchmetrics (from avalanche-lib)\n",
            "  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from avalanche-lib) (4.7.3)\n",
            "Collecting qpsolvers[open_source_solvers] (from avalanche-lib)\n",
            "  Downloading qpsolvers-4.3.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from avalanche-lib)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from avalanche-lib) (23.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib) (1.62.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib) (3.5.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib) (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown->avalanche-lib) (3.13.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->avalanche-lib) (4.12.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->avalanche-lib) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->avalanche-lib) (3.3.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib) (2.1.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics->avalanche-lib)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->avalanche-lib)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->avalanche-lib)\n",
            "  Downloading sentry_sdk-1.40.6-py2.py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.5/258.5 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->avalanche-lib)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib) (6.0.1)\n",
            "Collecting setproctitle (from wandb->avalanche-lib)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib) (1.4.4)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->avalanche-lib)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->avalanche-lib) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->avalanche-lib) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15->avalanche-lib) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=1.15->avalanche-lib) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=1.15->avalanche-lib) (2.1.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->avalanche-lib) (2.5)\n",
            "Requirement already satisfied: ecos>=2.0.8 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib) (2.0.13)\n",
            "Requirement already satisfied: cvxopt>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib) (1.3.2)\n",
            "Requirement already satisfied: scs>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib) (3.2.4.post1)\n",
            "Collecting piqp>=0.2.2 (from qpsolvers[open_source_solvers]->avalanche-lib)\n",
            "  Downloading piqp-0.2.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (959 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.0/960.0 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting highspy>=1.1.2.dev3 (from qpsolvers[open_source_solvers]->avalanche-lib)\n",
            "  Downloading highspy-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qpalm>=1.2.1 (from qpsolvers[open_source_solvers]->avalanche-lib)\n",
            "  Downloading qpalm-1.2.2-cp310-cp310-manylinux_2_17_x86_64.whl (737 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m737.2/737.2 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting daqp>=0.5.1 (from qpsolvers[open_source_solvers]->avalanche-lib)\n",
            "  Downloading daqp-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (458 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.0/459.0 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting proxsuite>=0.2.9 (from qpsolvers[open_source_solvers]->avalanche-lib)\n",
            "  Downloading proxsuite-0.6.3-0-cp310-cp310-manylinux_2_17_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting quadprog>=0.1.11 (from qpsolvers[open_source_solvers]->avalanche-lib)\n",
            "  Downloading quadprog-0.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.2/508.2 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib) (0.6.2.post8)\n",
            "Collecting clarabel>=0.4.1 (from qpsolvers[open_source_solvers]->avalanche-lib)\n",
            "  Downloading clarabel-0.7.1-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.15->avalanche-lib) (1.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->avalanche-lib) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->avalanche-lib)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.6.2->qpsolvers[open_source_solvers]->avalanche-lib) (0.1.7.post0)\n",
            "Collecting cmeel (from proxsuite>=0.2.9->qpsolvers[open_source_solvers]->avalanche-lib)\n",
            "  Downloading cmeel-0.53.3-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.15->avalanche-lib) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=1.15->avalanche-lib) (3.2.2)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from cmeel->proxsuite>=0.2.9->qpsolvers[open_source_solvers]->avalanche-lib) (2.0.1)\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7393 sha256=780f8cf0c61c34750e94069d8ea8c5172ad8f7f69de7e16c601030c6d4b9e635\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil, daqp, smmap, setproctitle, sentry-sdk, quadprog, piqp, lightning-utilities, highspy, docker-pycreds, dill, cmeel, qpsolvers, qpalm, pytorchcv, proxsuite, gitdb, clarabel, torchmetrics, GitPython, wandb, avalanche-lib\n",
            "Successfully installed GitPython-3.1.42 avalanche-lib-0.5.0 clarabel-0.7.1 cmeel-0.53.3 daqp-0.5.1 dill-0.3.8 docker-pycreds-0.4.0 gitdb-4.0.11 gputil-1.4.0 highspy-1.5.3 lightning-utilities-0.10.1 piqp-0.2.4 proxsuite-0.6.3 pytorchcv-0.0.67 qpalm-1.2.2 qpsolvers-4.3.1 quadprog-0.1.12 sentry-sdk-1.40.6 setproctitle-1.3.3 smmap-5.0.1 torchmetrics-1.3.1 wandb-0.16.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install torch transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8ObZdvN8F5w",
        "outputId": "ce676e38-e026-430d-a163-19bd8b8642b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting avalanche\n",
            "  Using cached avalanche-0.3.0.tar.gz (14 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from collections import OrderedDict\n",
        "\n",
        "def gelu(x):\n",
        "    \"\"\"Implementation of the gelu activation function.\"\"\"\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
        "\n",
        "class Config(object):\n",
        "    \"\"\"Configuration class to store the configuration of a `BertModel`.\"\"\"\n",
        "    def __init__(self,\n",
        "                 vocab_size,\n",
        "                 hidden_size=512,\n",
        "                 num_hidden_layers=6,\n",
        "                 num_attention_heads=8,\n",
        "                 intermediate_size=2048,\n",
        "                 dropout_prob=0.1,\n",
        "                 max_position_embeddings=512,\n",
        "                 type_vocab_size=2,\n",
        "                 initializer_range=0.02):\n",
        "        \"\"\"Constructs Config for BertModel.\"\"\"\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_hidden_layers = num_hidden_layers\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.intermediate_size = intermediate_size\n",
        "        self.hidden_dropout_prob = dropout_prob\n",
        "        self.attention_probs_dropout_prob = dropout_prob\n",
        "        self.max_position_embeddings = max_position_embeddings\n",
        "        self.type_vocab_size = type_vocab_size\n",
        "        self.initializer_range = initializer_range\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(cls, dict_object):\n",
        "        \"\"\"Constructs Config from a Python dictionary of parameters.\"\"\"\n",
        "        config = Config(vocab_size=None)\n",
        "        for (key, value) in dict_object.items():\n",
        "            config.__dict__[key] = value\n",
        "        return config\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    \"\"\"Layer normalization module.\"\"\"\n",
        "    def __init__(self, hidden_size, variance_epsilon=1e-12):\n",
        "        \"\"\"Constructs LayerNorm object for Transformer layer in BERT model.\"\"\"\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.gamma = nn.Parameter(torch.ones(hidden_size))\n",
        "        self.beta = nn.Parameter(torch.zeros(hidden_size))\n",
        "        self.variance_epsilon = variance_epsilon\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass of the LayerNorm layer.\"\"\"\n",
        "        u = x.mean(-1, keepdim=True)\n",
        "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
        "        return self.gamma * x + self.beta\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"Feed forward network with gelu activation.\"\"\"\n",
        "    def __init__(self, hidden_size, intermediate_size):\n",
        "        \"\"\"Constructs MLP object for Transformer layer in BERT model.\"\"\"\n",
        "        super(MLP, self).__init__()\n",
        "        self.dense_expansion = nn.Linear(hidden_size, intermediate_size)\n",
        "        self.dense_contraction = nn.Linear(intermediate_size, hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass of the MLP layer.\"\"\"\n",
        "        x = self.dense_expansion(x)\n",
        "        x = self.dense_contraction(gelu(x))\n",
        "        return x\n",
        "\n",
        "class Layer(nn.Module):\n",
        "    \"\"\"The Transformer layer.\"\"\"\n",
        "    def __init__(self, config):\n",
        "        \"\"\"Constructs Layer object for Transformer layer in BERT model based on config.\"\"\"\n",
        "        super(Layer, self).__init__()\n",
        "\n",
        "        self.hidden_size = config.hidden_size\n",
        "        self.num_attention_heads = config.num_attention_heads\n",
        "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
        "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "\n",
        "        self.attn_out = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.ln1 = LayerNorm(config.hidden_size)\n",
        "\n",
        "        self.mlp = MLP(config.hidden_size, config.intermediate_size)\n",
        "        self.ln2 = LayerNorm(config.hidden_size)\n",
        "\n",
        "    def split_heads(self, tensor, num_heads, attention_head_size):\n",
        "        \"\"\"Split hidden_size into num_heads * attention_head_size and transpose into shape [batch, num_heads, seq_len, attention_head_size].\"\"\"\n",
        "        new_shape = tensor.size()[:-1] + (num_heads, attention_head_size)\n",
        "        tensor = tensor.view(*new_shape)\n",
        "        return tensor.permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "    def merge_heads(self, tensor, num_heads, attention_head_size):\n",
        "        \"\"\"Transpose and then reshape into shape [batch, seq_len, hidden_size].\"\"\"\n",
        "        tensor = tensor.permute(0, 2, 1, 3).contiguous()\n",
        "        new_shape = tensor.size()[:-2] + (num_heads * attention_head_size,)\n",
        "        return tensor.view(new_shape)\n",
        "\n",
        "    def attn(self, q, k, v, attention_mask):\n",
        "        \"\"\"Attention mechanism for the Transformer layer.\"\"\"\n",
        "        mask = attention_mask == 1\n",
        "        mask = mask.unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        s = torch.matmul(q, k.transpose(-1, -2))\n",
        "        s = s / math.sqrt(self.attention_head_size)\n",
        "\n",
        "        s = torch.where(mask, s, torch.tensor(float('-inf')))\n",
        "\n",
        "        p = F.softmax(s, dim=-1)\n",
        "        p = self.dropout(p)\n",
        "\n",
        "        a = torch.matmul(p, v)\n",
        "        return a\n",
        "\n",
        "    def forward(self, x, attention_mask):\n",
        "        \"\"\"Forward pass of the Transformer layer in BERT.\"\"\"\n",
        "        q, k, v = self.query(x), self.key(x), self.value(x)\n",
        "\n",
        "        q = self.split_heads(q, self.num_attention_heads, self.attention_head_size)\n",
        "        k = self.split_heads(k, self.num_attention_heads, self.attention_head_size)\n",
        "        v = self.split_heads(v, self.num_attention_heads, self.attention_head_size)\n",
        "\n",
        "        a = self.attn(q, k, v, attention_mask)\n",
        "        a = self.merge_heads(a, self.num_attention_heads, self.attention_head_size)\n",
        "        a = self.attn_out(a)\n",
        "        a = self.dropout(a)\n",
        "        a = self.ln1(a + x)\n",
        "\n",
        "        m = self.mlp(a)\n",
        "        m = self.dropout(m)\n",
        "        m = self.ln2(m + a)\n",
        "\n",
        "        return m\n",
        "\n",
        "class Bert(nn.Module):\n",
        "    \"\"\"Custom BERT implementation.\"\"\"\n",
        "    def __init__(self, config_dict):\n",
        "        \"\"\"Constructs Bert model based on config_dict.\"\"\"\n",
        "        super(Bert, self).__init__()\n",
        "        self.config = Config.from_dict(config_dict)\n",
        "        self.embeddings = nn.ModuleDict({\n",
        "            'token': nn.Embedding(self.config.vocab_size, self.config.hidden_size, padding_idx=0),\n",
        "            'position': nn.Embedding(self.config.max_position_embeddings, self.config.hidden_size),\n",
        "            'token_type': nn.Embedding(self.config.type_vocab_size, self.config.hidden_size),\n",
        "        })\n",
        "\n",
        "        self.ln = LayerNorm(self.config.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            Layer(self.config) for _ in range(self.config.num_hidden_layers)\n",
        "        ])\n",
        "\n",
        "        self.pooler = nn.Sequential(OrderedDict([\n",
        "            ('dense', nn.Linear(self.config.hidden_size, self.config.hidden_size)),\n",
        "            ('activation', nn.Tanh()),\n",
        "        ]))\n",
        "\n",
        "    def save_model(self, path):\n",
        "        \"\"\"Save model to a file.\n",
        "\n",
        "        Args:\n",
        "            path (str): Path to the file where the model will be saved.\n",
        "        \"\"\"\n",
        "        torch.save(self.state_dict(), path)\n",
        "\n",
        "    @classmethod\n",
        "    def load_model(cls, config_dict, path):\n",
        "        \"\"\"Load model from a file.\n",
        "\n",
        "        Args:\n",
        "            config_dict (dict): Dictionary containing the configuration of the model.\n",
        "            path (str): Path to the model checkpoint.\n",
        "\n",
        "        Returns:\n",
        "            Bert: Bert model loaded from the checkpoint.\n",
        "        \"\"\"\n",
        "        model = cls(config_dict)\n",
        "        model.load_state_dict(torch.load(path))\n",
        "        return model\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
        "        \"\"\"Forward pass of the model to generate embeddings.\n",
        "\n",
        "        Args:\n",
        "            input_ids (torch.Tensor): Input tensor of shape [batch_size, seq_len] containing token ids of tokens in the input sequence.\n",
        "            attention_mask (torch.Tensor, optional): Mask to avoid performing attention on padding token indices. Defaults to None.\n",
        "            token_type_ids (torch.Tensor, optional): Segment token indices to indicate first and second portions of the inputs. Defaults to None.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor]: Tuple of output embeddings of shape [batch_size, seq_len, hidden_size] and pooled output of shape [batch_size, hidden_size].\n",
        "        \"\"\"\n",
        "        position_ids = torch.arange(input_ids.size(1), dtype=torch.long, device=input_ids.device)\n",
        "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones_like(input_ids)\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros_like(input_ids)\n",
        "\n",
        "        # BUG 7: Embeddings should be summed together, not concatenated\n",
        "        x = (self.embeddings['token'](input_ids) +\n",
        "             self.embeddings['position'](position_ids) +\n",
        "             self.embeddings['token_type'](token_type_ids))\n",
        "        x = self.dropout(self.ln(x))\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, attention_mask)\n",
        "\n",
        "        o = self.pooler(x[:, 0])\n",
        "        return x, o\n"
      ],
      "metadata": {
        "id": "xwliFn7kPeBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "config_dict = {\n",
        "    'vocab_size': 30000,  # Vocabulary size of the pre-trained BERT model\n",
        "    'hidden_size': 128,  # Size of the hidden layers\n",
        "    'num_hidden_layers': 2,  # Number of transformer blocks or layers\n",
        "    'num_attention_heads': 2,  # Number of attention heads in the multi-head attention layers\n",
        "    'intermediate_size': 512,  # Size of the intermediate (feed-forward) layers\n",
        "    'dropout_prob': 0.1,  # Dropout probability for regularization\n",
        "    'max_position_embeddings': 512,  # Maximum position index for positional embeddings\n",
        "    'type_vocab_size': 2,  # Number of segments (e.g., sentence A and sentence B for NSP task)\n",
        "    'initializer_range': 0.02,  # Range for weight initialization\n",
        "}\n",
        "# Create and save the model\n",
        "model = Bert(config_dict)\n",
        "model.save_model(\"/content/my_custom_bert_model.pth\")\n",
        "\n",
        "# Load the model for predictions\n",
        "loaded_model = Bert.load_model(config_dict, \"/content/my_custom_bert_model.pth\")\n",
        "\n",
        "# Perform predictions\n",
        "input_ids = torch.randint(0, 10000, (32, 128))  # Example input\n",
        "attention_mask = torch.ones_like(input_ids)  # Assuming no padding in the example\n",
        "\n",
        "# Get output embeddings and pooled output\n",
        "output_embeddings, pooled_output = loaded_model(input_ids, attention_mask)\n",
        "\n",
        "# Now, let's use a tokenizer for processing a sentence\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
      ],
      "metadata": {
        "id": "LVi3aTlg1HxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"setfit/20_newsgroups\")\n",
        "\n",
        "# Choose a sentence from the dataset for prediction\n",
        "sentence = dataset[\"train\"][18][\"text\"]\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# Perform prediction\n",
        "with torch.no_grad():\n",
        "    output_embeddings, pooled_output = model(**tokens)\n",
        "\n",
        "# Assuming you have a linear layer for classification, apply softmax to get probabilities\n",
        "linear_layer = torch.nn.Linear(config_dict['hidden_size'], 20)  # Replace num_classes with your actual number of classes\n",
        "logits = linear_layer(pooled_output)\n",
        "probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "# Print the predicted probabilities\n",
        "print(\"Predicted Probabilities:\", probabilities.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcEGDhDv9tKi",
        "outputId": "e6e2bbb7-b6ec-45d8-f8fb-730447fd6e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
            "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Probabilities: [[0.0498465821146965, 0.057605985552072525, 0.03751376271247864, 0.06362807750701904, 0.03204759210348129, 0.05146433040499687, 0.056139227002859116, 0.05091714859008789, 0.035728730261325836, 0.06136772036552429, 0.038834139704704285, 0.07049059867858887, 0.0482066385447979, 0.038755446672439575, 0.04320911318063736, 0.04162205010652542, 0.041218679398298264, 0.08356966823339462, 0.050484444946050644, 0.04735006392002106]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the 19th row in the \"text\" column\n",
        "text_19th_row = dataset['train']['text'][18]\n",
        "\n",
        "print(text_19th_row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxPJfvlb_n5x",
        "outputId": "f2eeace1-b598-41cb-b79e-f07c8a0dab4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I would like to be able to amplify a voltage signal which is\n",
            "output from a thermocouple, preferably by a factor of\n",
            "100 or 1000 ---- so that the resulting voltage can be fed\n",
            "more easily into a personal-computer-based ADC data\n",
            "acquisition card.\n",
            "\n",
            "Might anyone be able to point me to references to such\n",
            "circuits?  I have seen simple amplifier circuits before, but\n",
            "I am not sure how well they work in practice.\n",
            "\n",
            "In this case, I'd like something which will amplify sufficiently\n",
            "\"nicely\" to be used for thermocouples (say, a few degrees\n",
            "accuracy or better).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = dataset[\"train\"][18][\"label\"]\n",
        "\n",
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4_R1bli-lDu",
        "outputId": "aa35b4e9-3db2-48b5-9bf5-6800c61d2a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentence\n",
        "sentence = \"This is an example sentence.\"\n",
        "\n",
        "# Tokenize the input sentence\n",
        "tokens = tokenizer(sentence, return_tensors='pt')\n",
        "input_ids = tokens['input_ids']\n",
        "attention_mask = tokens['attention_mask']\n",
        "\n",
        "# Perform predictions on the sentence\n",
        "output_embeddings, pooled_output = loaded_model(input_ids, attention_mask)\n",
        "\n",
        "# Output the results\n",
        "print(\"Output Embeddings Shape:\", output_embeddings.shape)\n",
        "print(\"Pooled Output Shape:\", pooled_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtbAC4WE4BOf",
        "outputId": "1741faa8-dd23-4515-b5f0-bee0ae0e253c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output Embeddings Shape: torch.Size([1, 8, 128])\n",
            "Pooled Output Shape: torch.Size([1, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loMufhRf4p80",
        "outputId": "6d726f3f-bd59-4294-f4a2-4aaf0f38a9dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0135,  1.7678, -2.6319,  ..., -0.4088,  1.0544, -0.0797],\n",
            "         [-1.2703, -1.2979, -0.5269,  ..., -0.4693,  1.0385,  1.6049],\n",
            "         [ 0.9008,  0.6688, -2.7968,  ...,  1.5679, -0.9866,  0.3960],\n",
            "         ...,\n",
            "         [-0.1527, -0.2476, -0.4779,  ...,  0.6273,  0.5653, -0.5120],\n",
            "         [ 2.0031,  1.5730, -1.4441,  ..., -0.0067, -0.7860,  0.7499],\n",
            "         [ 0.7912, -0.2839, -2.2449,  ...,  1.2883, -0.2629, -0.3554]]],\n",
            "       grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    }
  ]
}